---
title: "Relatório 4 - software metrics"
output: html_notebook
author: "christiano Rossini Martins Costa"
---



#RQ1. Are there correlations among software metrics?

##Base balanceada

```{r}
library(corrplot)

kernelDsb <- read.csv(file = "/home/christiano/Dropbox/trabalhos/disciplina_mineracao/aulas/04-05/random_undersampling/kernel_data_balanced.csv", stringsAsFactors = FALSE)

kernelDsb$Affected <- factor(kernelDsb$Affected)
 
cm <- cor(kernelDsb[,1:27])

corrplot(cm, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)

col<- colorRampPalette(c("blue", "white", "red"))(20)
heatmap(x = cm, col = col, symm = TRUE)

```


##Base não balanceada

```{r}
kernelDsu <- read.csv(file = "/home/christiano/Dropbox/trabalhos/disciplina_mineracao/aulas/04-05/unbalanced/kernel_data.csv", stringsAsFactors = FALSE)

kernelDsu$Affected <- factor(kernelDsu$Affected)

cm <- cor(kernelDsu[,1:27])

corrplot(cm, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)

col<- colorRampPalette(c("blue", "white", "red"))(20)
heatmap(x = cm, col = col, symm = TRUE)
```


#RQ2. Are the software metrics able to represent functions with reported vulnerabilities?

```{r}

library(ggplot2)
library(dplyr)

kernelDsbVulnerable <- kernelDsb %>% filter(Affected=="VULNERABLE")
kernelDsbNeutral <- kernelDsb %>% filter(Affected=="NEUTRAL")

kernelDsbVulnerable$Affected <- NULL
kernelDsbVulnerable$Fold <- NULL
kernelDsbNeutral$Affected <- NULL
kernelDsbNeutral$Fold <- NULL

dfPvalueResult <- data.frame()
i=1
for(column in names(kernelDsbNeutral)){
  pvalue <- wilcox.test(kernelDsbNeutral[[column]], kernelDsbVulnerable[[column]])$p.value
  dfPvalueResult[i,"metrica"] <- column
  dfPvalueResult[i,"pvalue"] <- pvalue
  i <- i + 1
}
```

### Resultado do teste estatístico de wilcoxon das métricas "Vulnerable" e "Neutral"

```{r}
dfPvalueResult
```

A partir dos valores de p-value encontrados, verifica-se que todas as métricas são menores que 0,05, o que significa que estão na faixa de 95% de certeza de que as métricas são estatisticamente relevantes para a variável "Affected"

### Visualização da distribuição de algumas métricas em boxplot, com transformação logarítmica na base 2
```{r}
kernelDsb %>% ggplot(aes(Affected, AltCountLineCode)) + geom_boxplot() + scale_y_continuous(trans = "log2")
kernelDsb %>% ggplot(aes(Affected, CountInput)) + geom_boxplot() + scale_y_continuous(trans = "log2")
kernelDsb %>% ggplot(aes(Affected, CountLineBlank)) + geom_boxplot() + scale_y_continuous(trans = "log2")
kernelDsb %>% ggplot(aes(Affected, CountLineCodeDecl)) + geom_boxplot() + scale_y_continuous(trans = "log2")
kernelDsb %>% ggplot(aes(Affected, CountLineComment)) + geom_boxplot() + scale_y_continuous(trans = "log2")
kernelDsb %>% ggplot(aes(Affected, CountLinePreprocessor)) + geom_boxplot() + scale_y_continuous(trans = "log2")
kernelDsb %>% ggplot(aes(Affected, CountPath)) + geom_boxplot() + scale_y_continuous(trans = "log2")
kernelDsb %>% ggplot(aes(Affected, CountStmt)) + geom_boxplot() + scale_y_continuous(trans = "log2")
kernelDsb %>% ggplot(aes(Affected, CountStmtEmpty)) + geom_boxplot() + scale_y_continuous(trans = "log2")
kernelDsb %>% ggplot(aes(Affected, Cyclomatic)) + geom_boxplot() + scale_y_continuous(trans = "log2")
kernelDsb %>% ggplot(aes(Affected, CyclomaticStrict)) + geom_boxplot() + scale_y_continuous(trans = "log2")
kernelDsb %>% ggplot(aes(Affected, Knots)) + geom_boxplot() + scale_y_continuous(trans = "log2")
  
 
```

#RQ3. How effective are machine learning techniques to predict vulnerable functions? 

```{r}

####################################################### Load Library ###################################################################
library(RWeka)
library(e1071)
library(gmodels)
library(C50)
library(caret)
library(irr)
library(randomForest)

library(dplyr)

####################################################### Functions ###################################################################

# Precision
precision <- function(tp, fp){
  
  precision <- tp/(tp+fp)
  
  return(precision)
}

# Recall
recall <- function(tp, fn){
  
  recall <- tp/(tp+fn)
  
  return(recall)
}

# F-measure
f_measure <- function(tp, fp, fn){
  
  f_measure <- (2*precision(tp,fp)*recall(tp,fn))/(recall(tp,fn) + precision(tp, fp))
  
  return(f_measure)
}

measures <- function(test, pred){
  
  true_positive <- 0
  true_negative <- 0
  false_positive <- 0
  false_negative <- 0
  
  test <- test=="VULNERABLE"
  pred <- pred=="VULNERABLE"
  
  for(i in 1:length(pred)){
    if(test[i] == TRUE && pred[i] == TRUE){
      true_positive <- true_positive + 1
    }else if(test[i] == FALSE && pred[i] == FALSE){
      true_negative <- true_negative + 1
    }else if(test[i] == FALSE && pred[i] == TRUE){
      false_negative <- false_negative + 1
    }else if(test[i] == TRUE && pred[i] == FALSE){
      false_positive <- false_positive + 1
    }
  }
  
  measures <- c(precision(true_positive,false_positive), 
                recall(true_positive,false_negative), 
                f_measure(true_positive,false_positive,false_negative))
  
  return(measures)
}

####################################################### Techniques ###################################################################

executeJ48 <- function(dataset, folds){
  results <- lapply(folds, function(x) {
    train <- dataset[-x, ]
    test <- dataset[x, ]
    model <- J48(train$Affected~ ., data = train)
    pred <- predict(model, test)
    
    results <- measures(test$Affected, pred)
    
    return(results)
  })
  
}

executeNaiveBayes <- function(dataset, folds){
  results <- lapply(folds, function(x) {
    train <- dataset[-x, ]
    test <- dataset[x, ]
    model <- naiveBayes(train, train$Affected, laplace = 1)
    pred <- predict(model, test)
    
    results <- measures(test$Affected, pred)
    
    return(results)
  })
  
}

executeC50 <- function(dataset, folds){
  results <- lapply(folds, function(x) {
    train <- dataset[-x, ]
    test <- dataset[x, ]
    model <- C5.0(train, train$Affected)
    pred <- predict(model, test)
    
    results <- measures(test$Affected, pred)
    
    return(results)
  })
  
}

executeSVM <- function(dataset, folds){
  results <- lapply(folds, function(x) {
    train <- dataset[-x, ]
    test <- dataset[x, ]
    model <- svm(train$Affected~ ., data = train)
    pred <- predict(model, test)
    
    results <- measures(test$Affected, pred)
    
    return(results)
  })
  
}

executeOneR <- function(dataset, folds){
  results <- lapply(folds, function(x) {
    train <- dataset[-x, ]
    test <- dataset[x, ]
    model <- OneR(train$Affected~ ., data = train)
    pred <- predict(model, test)
    
    results <- measures(test$Affected, pred)
    
    return(results)
  })
  
}

executeJRip <- function(dataset, folds){
  results <- lapply(folds, function(x) {
    train <- dataset[-x, ]
    test <- dataset[x, ]
    model <- JRip(train$Affected~ ., data = train)
    pred <- predict(model, test)
    
    results <- measures(test$Affected, pred)
    
    return(results)
  })
  
}

executeRandomForest <- function(dataset, folds){
  results <- lapply(folds, function(x) {
    train <- dataset[-x, ]
    test <- dataset[x, ]
    model <- randomForest(train$Affected~ ., data = train)
    pred <- predict(model, test)
    
    results <- measures(test$Affected, pred)
    
    return(results)
  })
}

executeSMO <- function(dataset, folds){
  results <- lapply(folds, function(x) {
    train <- dataset[-x, ]
    test <- dataset[x, ]
    model <- SMO(train$Affected~ ., data = train)
    pred <- predict(model, test)
    
    results <- measures(test$Affected, pred)
    
    return(results)
  })
}

####################################################### DCL Analysis ###################################################################

techniques <- c("J48", "NaiveBayes", "SVM", "oneR", "JRip", "RandomForest", "SMO")

dataset <- kernelDsb

set.seed(3)
folds <- createFolds(dataset$Affected, k =5)

resultsJ48 <- executeJ48(dataset, folds)
partial_results <- rowMeans(as.data.frame(resultsJ48), na.rm = TRUE)

resultsNaiveBayes <- executeNaiveBayes(dataset, folds)
partial_results <- rbind(partial_results, rowMeans(as.data.frame(resultsNaiveBayes), na.rm = TRUE) ) 

resultsSVM <- executeSVM(dataset, folds)
partial_results <- rbind(partial_results, rowMeans(as.data.frame(resultsSVM), na.rm = TRUE)) 

resultsOneR <- executeOneR(dataset, folds)
partial_results <- rbind(partial_results, rowMeans(as.data.frame(resultsOneR), na.rm = TRUE)) 

resultsJRip <- executeJRip(dataset, folds)
partial_results <- rbind(partial_results, rowMeans(as.data.frame(resultsJRip), na.rm = TRUE)) 

resultsRandomForest <- executeRandomForest(dataset, folds)
partial_results <- rbind(partial_results, rowMeans(as.data.frame(resultsRandomForest), na.rm = TRUE)) 

resultsSMO <- executeSMO(dataset, folds)
partial_results <- rbind(partial_results, rowMeans(as.data.frame(resultsSMO), na.rm = TRUE)) 

rownames(partial_results) <- c("J48", "NaiveBayes", "SVM", "oneR", "JRip", "RandomForest","SMO")
colnames(partial_results) <- c("Precision", "Recall", "F-measure")

```
## Tabela de efetividade 

Tabela de efetividade em termos de Precision, Recall e F-measure, com base em 7 técnicas de aprendizagem.

```{r}

partial_results

```





## Construção do bar plot utilizando a tabela de métricas anterior, mas com o cálculo de média.

```{r}

results <- partial_results

resultsMean <- mean(results[1,1:3])
resultsMean <- rbind(resultsMean, mean(results[2,1:3]))
resultsMean <- rbind(resultsMean, mean(results[3,1:3]))
resultsMean <- rbind(resultsMean, mean(results[4,1:3]))
resultsMean <- rbind(resultsMean, mean(results[5,1:3]))
resultsMean <- rbind(resultsMean, mean(results[6,1:3]))
resultsMean <- rbind(resultsMean, mean(results[7,1:3]))

#results[,] <- lapply(results,function(x){ x[is.nan(x)]<-0;return(x)})

colnames(resultsMean) <- "mean"
rownames(resultsMean) <- techniques

resultsMean <- t(resultsMean)

barplot(resultsMean, 
        main="Techniques x Effectiveness",
        ylab="Effectiveness",
        xlab="Techniques", 
        col=c("red", "yellow", "green", "violet", "orange", "blue", "pink"), 
        ylim = c(0, 1),
        #legend = rownames(results_mean), 
        beside=TRUE)

```

